{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aneka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aneka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get('https://mindmates.onrender.com/api/mindmate/get-all')\n",
    "data = json.loads(data.text)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop(['password','__v','mates','meeting_url','profile','address','availability','name','anonymous','email'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp(arr):\n",
    "  str = ''\n",
    "  for i in arr:\n",
    "    str += i + ' '\n",
    "  return str\n",
    "\n",
    "def method(str, str1):\n",
    "  return str + str1\n",
    "\n",
    "def tokenizer(str):\n",
    "  tokens = word_tokenize(str)\n",
    "  tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stopwords.words('english')]\n",
    "  preprocessed_text = ' '.join(tokens)\n",
    "  return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expertise'] = df['expertise'].apply(temp)\n",
    "\n",
    "df['desc'] = df[['bio','expertise']].apply(lambda df : method(df['bio'], df['expertise']), 1)\n",
    "df = df.drop(['bio','expertise'], axis = 1)\n",
    "\n",
    "df['tokens'] = df['desc'].apply(tokenizer)\n",
    "\n",
    "df = df.drop('desc', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open('df.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65cf30c7cf5f3b5e917dfde6</td>\n",
       "      <td>aim provide people space express environment g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65cf30ffcf5f3b5e917dfde8</td>\n",
       "      <td>goal empathetic practitioner creating secure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65d042055b76300445d69749</td>\n",
       "      <td>believe mental health key component success us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65d0424d5b76300445d69750</td>\n",
       "      <td>believe following passion creating mindful bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65d045cb5b76300445d69771</td>\n",
       "      <td>practice believe effectiveness therapy relies ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                                             tokens\n",
       "0  65cf30c7cf5f3b5e917dfde6  aim provide people space express environment g...\n",
       "1  65cf30ffcf5f3b5e917dfde8  goal empathetic practitioner creating secure t...\n",
       "2  65d042055b76300445d69749  believe mental health key component success us...\n",
       "3  65d0424d5b76300445d69750  believe following passion creating mindful bei...\n",
       "4  65d045cb5b76300445d69771  practice believe effectiveness therapy relies ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
